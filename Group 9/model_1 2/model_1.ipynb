{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa476b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skl2onnx import convert_sklearn\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('../censored_training_set.csv')\n",
    "\n",
    "# Let's specify the features and the target - Use all the features from the examples dataset\n",
    "# You should drop Ja and Nee\n",
    "y_train = data['checked']\n",
    "X_train = data.drop(['checked', 'Ja', 'Nee'], axis=1)\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "# We use the entire censored training dataset as our training set, and another dataset as our test set\n",
    "test_df = pd.read_csv(\"../censored_test_set.csv\")\n",
    "X_test = test_df.drop(['checked', 'Ja', 'Nee'], axis=1)\n",
    "y_test = test_df[\"checked\"]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_features_to_drop(keep_data):\n",
    "    columns_to_drop = [\n",
    "        col for col in data.columns if col not in keep_data and col not in [\"Ja\", \"Nee\", \"checked\"]\n",
    "    ]\n",
    "    return columns_to_drop"
   ],
   "id": "27bca40c7b3528ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a pipeline object with our selector and classifier\n",
    "# NOTE: You can create custom pipeline objects but they must be registered to onnx or it will not recognise them\n",
    "# Because of this we recommend using the onnx known objects as defined in the documentation\n",
    "keep_cols = [\n",
    " #censored_features \n",
    "]\n",
    "\n",
    "feature_selector = ColumnTransformer([\n",
    "        ('drop', 'drop', get_features_to_drop(keep_cols))\n",
    "    ], remainder=StandardScaler())\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=5, criterion='gini', max_depth=5)"
   ],
   "id": "dad040528cb93c91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pipeline = Pipeline(steps=[('feature selection', feature_selector),  ('classification', classifier)])",
   "id": "228848b9f052e1b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's train a simple model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Let's evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "original_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of the original model: ', original_accuracy)"
   ],
   "id": "9808ff971ba78a3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X_train.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ],
   "id": "6aadb53236c753bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model\n",
    "onnx.save(onnx_model, \"model_1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58700629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the model\n",
    "new_session = rt.InferenceSession(\"model_1.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx-example-main-AMLfW3nC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
